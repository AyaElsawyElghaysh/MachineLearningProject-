# MachineLearningProject-
here the description for each tack 
------------------
Task 1:
1. Gradient Descent with Regression
a. Given the following resources
i. sklearn.datasets.make_regression — scikit-learn 1.0.2 documentation
“dataset” with one feature only and a non-zero bias.
ii. Gradient Descent Optimization With Nadam From Scratch
iii. Gradient Descent in Python: Implementation and Theory
iv. What is a Loss Landscape? A visual exploration
v. How to visualize Gradient Descent using Contour plot in Python
vi. Visualizing the gradient descent method
b. Please use the above resources to implement the gradient descent
algorithm (mini-batch, batch, or stochastic, choose the easier option for you)
with the given regression dataset.
c. Follow the traditional ML pipeline steps as discussed.
d. Report the R
2
score and the RMSE of your problem.
e. Compare your final weights with the output from a Normal Equation solution.
f. Visualize the loss landscape according to the trainable parameters. “Bonus”
g. The estimated time to finish is 45 mins max.


-----------------------
Task2 
2. Gradient Descent with Logistic Regression
a. Given the following resources
i. sklearn.datasets.load_breast_cancer — scikit-learn 1.0.2
documentation
ii. https://www.geeksforgeeks.org/ml-kaggle-breast-cancer-wisconsin-d
iagnosis-using-logistic-regression/
iii. Example using scikit-learn: Breast cancer prediction
iv. Logistic Regression from Scratchc. The preprocessing step is important, so, please use the above resources to
ease the problem for you or read chapter 4 in Python Machine Learning
book.
d. Print out the classification report and explain your results.
e. Please choose a metric suitable for this medical task and explain the
behavior of the model based on that metric.
f. Please indicate whether or not the dataset is imbalanced and what could be
done to mitigate this situation either programmatically or theoretically. Note
that, if you choose to answer theoretically, then you need to express the
answer during the interview with a strong justification.
g. Compare your results with sklearn.linear_model.LogisticRegression —
scikit-learn 1.0.2 documentation.
h. Getting a testing accuracy over 96 is a bonus and getting an f1 score on the
testing set above 95 is a double bonus.
i. The estimated time to finish this task is 120 mins.


-------------------
Task3

Non-Linear Regression
a. Given the following resources
i. Data.npy, this dataset has two columns, the first one is the predictor
and the second is the label.
ii. Read chapter 4 in hands-on machine learning “polynomial
regression” or chapter 10 in Python machine learning. Or use the
following links.
iii. sklearn.preprocessing.PolynomialFeatures — scikit-learn 1.0.2
documentation
iv. Polynomial and Spline interpolation — scikit-learn 1.0.2 documentation
v. Underfitting vs. Overfitting — scikit-learn 1.0.2 documentation
vi. Robust linear estimator fitting — scikit-learn 1.0.2 documentation
b. Using the above resources, use the linear regression model from scikit-learn
or implement it yourself and modify the dataset so that the linear model can
fit the data properly. You can use the scikit-learn polynomial feature
engineering method or you can add the features yourself.
c. Test your model report the error rates and check whether or not there is
overfitting.


v. Logistic Regression from scratch - Philipp Muens
b. Using the above resources, please use the gradient descent algorithm and
implement the logistic regression model from scratch to solve the
classification problem above
